1.1. zookeeper 安装&配置
现在，我们开始使用三台机器来搭建一个Zookeeper集群。由于没有多余的服务器，这里就将三个Zk都安装到本地机器上，故称谓伪集群模式。

伪集群模式只是便于开发、普通测试，不能用于生产环境。当然，如果了解了伪集群模式下的安装和配置，生产环境下的配置，也是大致差不多的。

首先是下载。在apache的官方网站提供了好多镜像下载地址，然后找到对应的版本，目前最新的是3.4.13。

下载地址：

服务器.http://mirrors.cnnic.cn/apache/zookeeper/zookeeper-3.4.13/zookeeper-3.4.13.tar.gz

Windows下安装

把下载的zookeeper的文件解压到指定目录

C:\devtools\zookeeper-3.4.13>

1.1.1. 创建数据目录和日志目录：
提前为每一个伪节点创建日志目录、数据目录。

在安装目录下，为每一个伪节点创建一个日志目录，分别为 log/zoo-1、 log/zoo-2、 log/zoo-3：

![img](file:///C:\Users\qinglin\AppData\Local\Temp\ksohtml\wps2376.tmp.jpg)

为每一个伪节点创建一个数据目录，分别为 data/zoo-1、 data/zoo-2、 data/zoo-3。

1.1.2. 创建myid文件
myid文件的主要作用，是记录（伪）节点的编号。

myid文件是一个文本文件，文件名称为myid。

myid文件内容为一个数字，表示节点的编号。

在第一个（伪）节点数据目录 C:\devtools\zookeeper-3.4.13>data\zoo-1\ 文件夹下创建内容为 "1" 的myid文件。表示第一个节点的编号为1。

在第二个（伪）节点数据目录 C:\devtools\zookeeper-3.4.13>data\zoo-2\ 文件夹下创建内容为 "2" 的myid文件。表示第二个节点的编号为2。

在第三个（伪）节点数据目录 C:\devtools\zookeeper-3.4.13>data\zoo-3\ 文件夹下创建内容为 "3" 的myid文件。表示第三个节点的编号为3。

强调一下：myid文件中只有一个数字，即一个Server ID，id的范围是1~255，表示集群最多的节点个数为255个。

1.1.3. 创建和修改配置文件
在zookeeper的配置目录conf 目录下，有一个官方的配置文件样例——zoo_sample.cfg。

将配置文件的样例zoo_sample.cfg文件复制3分，为每一个节点复制一份，分别命名为zoo-1.cfg、zoo-2.cfg、zoo-3.cfg，应用于3个节点。

然后，需要修改每一个节点的配置文件，将前面建立的编号（Server ID）、日志目录、数据目录，配置进去。

首先，配置 （Server ID）编号、IP、端口。格式为：

server.id=host:port:port

在zookeeper集群中，每个节点都需要感知到整个集群是哪些节点组。在配置文件中，可以按照这样的格式进行配置，每一行都代表一个节点。

三个节点，配置的实例如下：

server.1=127.0.0.1:2888:3888

server.2=127.0.0.1:2889:3889

server.3=127.0.0.1:2890:3890

配置ID的时候，注意四点：

（1）清确保每个节点的myid文件中的id值不同，不能有相同id的节点；

（2）server.id=houst:port:port的id值，需要与所对应的节点数据目录下的myid中的di值保持一致。

（3）每一个节点的配置文件中，不仅仅是配置自己的那份，而是需要所有节点的id、ip、端口配置。

（4）Id配置中，需要配置两个端口。前一个端口（如上的2888）用于节点之间的通讯使用，后一个端口（如上的3888）用于选举leader主节点使用。在伪集群的模式下，两个端口必须修改每一个节点都不一样。在分布式集群模式下，不同节点的ip不同，可以不同节点的端口相同。

其次，配置数据目录dataDir。

每一个节点，都有自己的数据目录。数据目录是没有默认值的，必须配置。dataDir用于存储节点快照文件的目录。

每个节点只需要配置自己的数据目录。案例中zoo-1.conf的数据目录如下：

dataDir=C:\devtools\zookeeper-3.4.13\data\zoo-1

第三，配置服务端口

clientPort：参数clientPort用于配置当前节点的服务端口，客户端会通过该端口和Zk服务器创建连接，一般设置为2181。不同的节点，clientPort不能相同，可以按照编号，进行累加。

第四，配置时间相关选项

tickTime：配置单元时间。单元时间是Zookeeper的时间计算单元，其他的时间间隔都是使用tickTime的倍数来表示的。单元时间默认值为3000，单位是毫秒（ms），所以，可以不配置。

initLimit：节点的初始化时间。该参数用于Follower（从节点）启动，并完成从Leader（主节点）同步数据的时间。Follower服务器在启动过程中，会与Leader建立连接并完成对数据的同步，从而确定自己的起始状态。leader服务器允许Follower在initLimit时间内完成这个工作。该参数默认值：10，表示是参数tickTime值的10倍，必须配置，且为正整数。

syncLimit：心跳最大延迟周期。该参数用于配置Leader服务器和Follower之间进行心跳检测的最大延时时间。在Zk集群运行的过程中，Leader服务器会通过心跳检测来确定Follower服务器是否存活。如果Leader服务器在syncLimit时间内无法获取到Follower的心跳检测响应，那么Leader就会认为该Follower已经脱离了和自己的同步。该参数默认值：5，表示是参数tickTime值的5倍，必须配置，且为正整数。

1.1.4. 配置文件实例
为了给出一个完整的直观体验，下面给出三份配置文件实际的代码。

第一个节点的配置文件zoo-1.conf

tickTime=4000

initLimit = 10

syncLimit = 5

dataDir = C:/devtools/zookeeper-3.4.13/data/zoo-1/

clientPort = 2181

server.1 = 127.0.0.1:2888:3888

server.2 = 127.0.0.1:2889:3889

server.3 = 127.0.0.1:2890:3890

第二个节点的配置文件zoo-2.conf

tickTime=4000

initLimit = 10

syncLimit = 5

dataDir = C:/devtools/zookeeper-3.4.13/data/zoo-2/

clientPort = 2182

server.1 = 127.0.0.1:2888:3888

server.2 = 127.0.0.1:2889:3889

server.3 = 127.0.0.1:2890:3890

第三个节点的配置文件zoo-3.conf

tickTime=4000

initLimit = 10

syncLimit = 5

dataDir = C:/devtools/zookeeper-3.4.13/data/zoo-3/

clientPort = 2183

server.1 = 127.0.0.1:2888:3888

server.2 = 127.0.0.1:2889:3889

server.3 = 127.0.0.1:2890:3890

通过三个配置文件，可以看出，每个节点的server id 的配置，都是全量配置。每一个节点的数据目录dataDir 和对外服务端口clientPort，则仅仅负责自己的那份。

1.1.5. 修改启动命令
在bin目录下，通过复制zkServer.cmd文件，为每一个伪节点创建一个启动文件，分别为 zkServer-1.cmd、zkServer-2.cmd、zkServer-3.cmd。

主要是为每一个节点增加配置文件（ZOOCFG）、日志目录ZOO_LOG_DIR的设置。

修改之后，第一个节点的启动命令 zkServer-1.cmd代码如下：

setlocal

call "%~dp0zkEnv.cmd"

set ZOOCFG=C:\devtools\zookeeper-3.4.13\conf\zoo-1.cfg

set ZOO_LOG_DIR=C:\devtools\zookeeper-3.4.13\log\zoo-1

set ZOOMAIN=org.apache.zookeeper.server.quorum.QuorumPeerMain

echo on

call %JAVA% "-Dzookeeper.log.dir=%ZOO_LOG_DIR%" "-Dzookeeper.root.logger=%ZOO_LOG4J_PROP%" -cp "%CLASSPATH%" %ZOOMAIN% "%ZOOCFG%" %*

endlocal

1.1.6. 启动伪集群
打开一个window的命令控制台，进入到bin目录，并且启动zkServer-1.cmd，这个脚本中会启动第一个节点的java服务进程：

C:\devtools\zookeeper-3.4.13>cd bin

C:\devtools\zookeeper-3.4.13\bin>

C:\devtools\zookeeper-3.4.13\bin > zkServer-1.cmd

zookeeper集群需要有1/2以上的节点启动，才能完成集群的启动，对外提供服务。所以，至少需要再启动一个节点。

打开另外一个window的命令控制台，进入到bin目录，并且启动zkServer-2.cmd，这个脚本中会启动第一个节点的java服务进程：

C:\devtools\zookeeper-3.4.13>cd bin

C:\devtools\zookeeper-3.4.13\bin>

C:\devtools\zookeeper-3.4.13\bin > zkServer-2.cmd

由于这里没有使用后台服务启动的模式，所以，这两个节点服务的窗口，在服务期间，不能关闭。

如何验证集群已经成功启动呢？

方法一：

可以通过jps命令，可以看到QuorumPeerMain的进程的数量。

C:\devtools\zookeeper-3.4.13\bin > jps

方法二：

启动zookeeper 客户端，运行查看一下，是否能连接集群。如果能够成功连接，这个时候zookeeper已经安装成功了，

C:\devtools\zookeeper-3.4.13\bin> ./zkCli.cmd -server 127.0.0.1:2181

windows下，Zookeeper是通过.cmd的批处理命令运行的，默认没有提供以windows服务的方式运行的方案。

避免每次关闭后，再启动还需要使用cmd，十分的不方便，可以通过工具prunsrv 来将zookeeper做成 windows 服务，将zookeeper服务化管理。