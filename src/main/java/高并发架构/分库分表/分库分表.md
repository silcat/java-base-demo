# 问题与挑战
* 阿里巴巴开发手册提出但表行数超过500万行或者单表容量超过2GB，数据库性能还会下降；
* 当数据库单表数据量到达一定量级，导致内存不能无法存储全部索引，导致sql查询产生磁盘IO，使得myql性能急剧下降；
* 当业务高速增长，单数据库面临高速增长高并发读写的访问，当到达一定量级，master数据库无法承担写操作压力
# 分库分表
* 当单数据库无法面对高速增长的并发读写访问时， 
    * 读写分离：配置从库作为读库，主库作为写库
    * 垂直拆分：将单库按照业务拆分，一个微服务一个数据库
    * 垂直拆分： 微服务对应数据库进行分库
* 当单表数据量过大
    * 水平拆分：将单表拆分为多表，提高单表查询性能 
    * 垂直拆分：将单表列字段拆分形成多表
# 分库分表带来的问题与挑战   
* 分库分表后，开发人员需要知道某个数据需要从哪个分库哪个分表获取
* 分库分表后，排序，数据聚合等操作如何处理
* 分库分表跨库事务如何处理
* 唯一键不能使用数据库自增键作为主键
# 分库分表介绍 
## 水平分表
* 只分表：将db库中的user表拆分为2个分表，user_0和user_1，这两个表还位于同一个库中。
* 只分库：将db库拆分为db_0和db_1两个库，同时在db_0和db_1库中各自新建一个user表，db_0.user表和db_1.user表中各自只存原来的db.user表中的部分数据。
* 分库分表：将db库拆分为db_0和db_1两个库，db_0中包含user_0、user_1两个分表，db_1中包含user_2、user_3两个分表。
##垂直分表
* 把主码和一些列放到一个表，然后把主码和另外的列放到另一个表中。
## 优点
* 分库的好处： 降低单台机器的负载压力，提升写入性能
* 分表的好处： 提高数据操作的效率。举个例子说明，比如user表中现在有4000w条数据，此时我们需要在这个表中增加（insert）一条新的数据，insert完毕后，数据库会针对这张表重新建立索引，4000w行数据建立索引的系统开销还是不容忽视的。但是反过来，假如我们将这个表分成4 个table呢，从user_0一直到user_3，4000w行数据平均下来，每个子表里边就只有1000W行数据，这时候我们向一张 只有1000W行数据的table中insert数据后建立索引的时间就会下降，从而提高DB的运行时效率，提高了DB的并发量。除了提高写的效率，更重要的是提高读的效率，提高查询的性能。当然分表的好处还不止这些，还有诸如写操作的锁操作等，都会带来很多显然的好处。

#分表键设计
##主键id生成
* 小规模：自增id+步长
* 大规模：分布式id
##单个分表键  
* 业务逻辑主体就是用户，可使用用户对应的字段作为分表键，如userId
* 业务逻辑主体就是卖家，可使用卖家对应的字段作为分表键，如loanId
* 日志检索类：数字（字符串）类型与时间类型字段相结合作为分表键
##多个分表键
````
选择分表键：uid ,order_id,shop_id，
````
* 定义
    * 主分表键=主维度，在主维度上，数据能够增删改查；
    * 辅助分表键=辅维度，在辅助维度上，只能进行数据查询
 
* 在主维度上全表扫描
    * 场景：查询条件是不包含分表键的
    * 场景：辅助维度的查询请求的量很小，并且是运营查询，对性能要求不高 多维度数据进行冗余同步
        * 问题：如根据uid分了4个库，32张表，主维度：uid 辅助维度：shop_id，其中很少查询shop_id
        * 实现方式：以4个线程去并发查询32张表，最终把结果合并输出
    * 场景：辅助维度的查询请求的量也很可观，不能直接使用第一种全表扫描的方式   
        * 问题：如根据uid分了4个库，32张表，主维度：uid 辅助维度：shop_id，其中经常查询shop_id，
        * 实现方式：通过binlog的方式，将shop_id的数据同步到 各个根据uid所分的 分库与分表,根据shop_id命中的分库与分表包含所需数据。
* 二维巧妙归一维
    * 场景：辅助维度其实有的时候也是主维度,辅助维度和主维度其实可以通过将主维度和辅助维度的值进行信息共享
        * 问题：如根据uid分了4个库，32张表，主维度：uid 辅助维度：order_id，order_id根据uid前6位其实是一一对应的,
        * 实现方式：如果SQL中带有的order_id维度，uid进行Hash取模路由，结果是一致的。
* 建立索引表
    * 场景：主副维度是一一对应的。      
         * 问题：如根据shop_id分了4个库，32张表，主维度：shop_id 辅助维度：order_id，order_id与shop_id是一一对应的,  
          * 实现方式：根据order_id分库分表建立order_id与shop_id的关系表，先根据order_id查关系表得出shop_id,根据shop_id查出主数据。
* 冗余全量表 
    * 场景：主副维度是一一对应的。  
         * 问题：如根据shop_id，order_id分别了4个库，32张表，主维度：shop_id 辅助维度：order_id
         * 实现方式：根据不同的分表键选择冗余全量表，直接查询数据        
##老表第一次分库分表
* 双写迁移方案：![](img/双写迁移.PNG)
* 建议第一次一开始上来就是 32 个库，每个库 32 个表，那么总共是 1024 张表，这个绝对够用
# 数据库扩容设计方案
##问题
* 之前存在4个数据库，现在需要扩容至8个数据库，分表键片规则由uid%4变为uid%5，导致扩容后无法命中在原有的数据库上了，需要量数据需要迁移。
## 停服迁移
````
预估停服时间，发布停服公告

停服，通过事先做好的数据迁移工具，按照新的分片规则，进行迁移

修改分片规则

启动服务
```` 

## 升级从库
* 1,2,3,4库为主库，F1,F2,F3,F4为从库，主副库数据相同
* 数据库扩容后为8个库，数据库编号变为1库为1库，F1为5库，2库为1库，F2为6库，3库为3库，F4为7库，4库为4库，F4为8库
    * 也就是：将原来n库分为n库和n+N库，其中新扩容的数据库数量
    * 因为主从库数据相同，无需迁移数据，只需要变更一下分片配置即可，通过配置中心更新，无需重启。
    * 分库后各个数据冗余数据可根据需要择时删除，不影响线上
    * 将新扩容的数据再新添加从库即可
## range与hash结合
* 将uid分为[1,1000w],[1000w,2000w]...不同range，不同range对应不同数据库集合group0，group1.....
* 如group0对应数据库1,2,3库，若uid=200则映射group0，group0内部根据uid%3取模，则uid=200对应group0 中1库。
* group0 中1库中再根据uid%9取模进行分表
* 若需要扩容则新增group，而原有数据不需要迁移
##一致性hash分库分表
* 问题：uid为分表键, 现在A(IP:1),B(100)两个数据，需扩容C(30),D(50)两个数据库
* hash环分布：0->A(1)->C(30)->D(50)->B(100)->0,若uid hash%32后取值为40
    * 扩容前：路由下个距离自己最近的节点B(100)
    * 扩容后：路由下个距离自己最近的节点D(50)
    * 将B的数据迁移到D中，而其他节点不移动
## 其他
*对于海量数据，且有一定的并发量的分库分表，绝不是引入某一个分库分表中间件就能解决问题，而是一项系统的工程。
* 需要分析整个表相关的业务，让合适的中间件做它最擅长的事情。
    * 分表键的查询走分库分表，
    * 一些模糊查询，或者多个不固定条件筛选则走es，
    * 海量存储则交给HBase。
* 一个实践是利用 32 * 32 来分库分表，即分为 32 个库，每个库里一个表分为 32 张表。一共就是 1024 张表。
* 路由的规则，orderId 模 32 = 库，orderId / 32 模 32 = 表
* 扩容的时候，呈倍数扩容，4 台服务器，扩到 8 台服务器，再到 16 台服务器。
* 由 dba 负责将原先数据库服务器的库，迁移到新的数据库服务器上去，库迁移是有一些便捷的工具的。
## 分库分表中间件
* mycat
    * 这种 proxy 层方案的缺点在于需要部署，自己运维一套中间件，运维成本高，但是好处在于对于各个项目是透明的，如果遇到升级之类的都是自己中间件那里搞就行了。  
* ShardingSphere 
    * 优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高，
    * 缺点遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要耦合 Sharding-jdbc 的依赖；
    * 转载：https://www.cnblogs.com/qdhxhz/p/11688371.html
* 用ShardingSphere     

  

        
        

